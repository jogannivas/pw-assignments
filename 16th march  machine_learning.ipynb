{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a9b65ce-d0ba-428e-b5be-7eadd709f710",
   "metadata": {},
   "source": [
    "Q1: Define overfitting and underfitting in machine learning. What are the consequences of each, and how can they be mitigated?\n",
    "\n",
    "\n",
    "Underfitting means that your model makes accurate, but initially incorrect predictions. In this case, train error is large and val/test error is large too. \n",
    "\n",
    "Overfitting means that your model makes not accurate predictions. In this case, train error is very small and val/test error is large.\n",
    "\n",
    "An underfit model results in high prediction errors for both training and test data. An overfit model gives a very low prediction error on training data, but a very high prediction error on test data. Both types of models result in poor accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6072fc1-5b0c-46e8-ad4d-4596b7f5078f",
   "metadata": {},
   "source": [
    "Q2: How can we reduce overfitting? Explain in brief.\n",
    "\n",
    "Early stopping. Early stopping pauses the training phase before the machine learning model learns the noise in the data .\n",
    "\n",
    "Pruning. You might identify several features or parameters that impact the final prediction when you build a model.\n",
    "\n",
    "Regularization. \n",
    "\n",
    "Ensembling. .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc02d67c-1324-45a2-8417-5d6cf050a03e",
   "metadata": {},
   "source": [
    "Q3: Explain underfitting. List scenarios where underfitting can occur in ML.\n",
    "\n",
    "Underfitting is a scenario in data science where a data model is unable to capture the relationship between the input and output variables accurately, generating a high error rate on both the training set and unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46921ae1-96b4-468d-a7a5-54f4acc86a16",
   "metadata": {},
   "source": [
    "Q4: Explain the bias-variance tradeoff in machine learning. What is the relationship between bias and variance, and how do they affect model performance?\n",
    "\n",
    "In machine learning, the bias–variance tradeoff is the property of a model that the variance of the parameter estimated across samples can be reduced by increasing the bias in the estimated parameters.\n",
    "\n",
    "Bias and variance are inversely connected. It is impossible to have an ML model with a low bias and a low variance. When a data engineer modifies the ML algorithm to better fit a given data set, it will lead to low bias—but it will increase variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee695436-dae6-47c3-ae57-ed912aee7d65",
   "metadata": {},
   "source": [
    "Q5: Discuss some common methods for detecting overfitting and underfitting in machine learning models. How can you determine whether your model is overfitting or underfitting?\n",
    "\n",
    " We can determine whether a predictive model is underfitting or overfitting the training data by looking at the prediction error on the training data and the evaluation data. Your model is underfitting the training data when the model performs poorly on the training data.Overfitting can be identified by checking validation metrics such as accuracy and loss. The validation metrics usually increase until a point where they stagnate or start declining when the model is affected by overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba7e42c-0e5d-4dc1-a947-f66668ddeb04",
   "metadata": {},
   "source": [
    "Q6: Compare and contrast bias and variance in machine learning. What are some examples of high bias and high variance models, and how do they differ in terms of their performance?\n",
    "\n",
    "Bias and variance are inversely connected. It is impossible to have an ML model with a low bias and a low variance. When a data engineer modifies the ML algorithm to better fit a given data set, it will lead to low bias—but it will increase variance.\n",
    "\n",
    "Examples of high-bias machine learning algorithms include: Linear Regression, Linear \n",
    "\n",
    "Discriminant Analysis and Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f264581-d954-482a-a6bd-c395496a0f90",
   "metadata": {},
   "source": [
    "Q7: What is regularization in machine learning, and how can it be used to prevent overfitting? Describe some common regularization techniques and how they work.\n",
    "\n",
    " Regularization refers to techniques that are used to calibrate machine learning models in order to minimize the adjusted loss function and prevent overfitting or underfitting.\n",
    " \n",
    "Ridge Regression (L2 Norm)\n",
    "Lasso (L1 Norm)\n",
    "Dropout.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e486a85-aefd-4eee-b886-dd914bfbf4e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
