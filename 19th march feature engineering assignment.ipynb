{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd662b4b-899b-44b4-948b-bcf90eb184cf",
   "metadata": {},
   "source": [
    "#Q1\n",
    "'''Min-Max scaling, also known as normalization, is a data preprocessing technique used to rescale numerical features within a specific range. The purpose of Min-Max scaling is to transform the data so that it falls within a predetermined range, typically between 0 and 1. This normalization technique is useful when the range of values in different features varies significantly.\n",
    "\n",
    "The formula for Min-Max scaling is as follows:\n",
    "\n",
    "scaled_value = (value - min_value) / (max_value - min_value)\n",
    "\n",
    "Let's say we have a dataset that contains a feature called \"Income,\" which represents the income of individuals. The minimum income in the dataset is $20,000, and the maximum income is $100,000. We want to scale this feature using Min-Max scaling.\n",
    "\n",
    "Suppose we have an individual with an income of $40,000. Using the Min-Max scaling formula, we can calculate the scaled value as follows:\n",
    "\n",
    "scaled_value = ($40,000 - $20,000) / ($100,000 - $20,000) = 0.25\n",
    "\n",
    "So, the scaled value for an income of $40,000 would be 0.25.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ba5d24-80bd-4463-99f4-fe79d441c34d",
   "metadata": {},
   "source": [
    "#Q2\n",
    "'''The Unit Vector technique, also known as vector normalization or feature scaling, is a data preprocessing method that aims to transform numerical features so that they have a unit norm. Unlike Min-Max scaling, which scales the values within a specific range, the Unit Vector technique focuses on the direction of the data rather than its magnitude.\n",
    "\n",
    "Let's consider an individual with a height of 170 cm and a weight of 65 kg. To calculate the unit vector, we first need to calculate the Euclidean norm of the vector (height, weight). In this case:\n",
    "\n",
    "||vector|| = sqrt((170^2) + (65^2)) = sqrt(28900 + 4225) = sqrt(33125) ≈ 181.8\n",
    "\n",
    "scaled_height = 170 / 181.8 ≈ 0.935\n",
    "scaled_weight = 65 / 181.8 ≈ 0.358\n",
    "\n",
    "Thus, the scaled values for height and weight would be approximately 0.935 and 0.358, respectively.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8b1256-dbeb-42b2-ace4-96b460248a00",
   "metadata": {},
   "source": [
    "#Q3\n",
    "'''\n",
    "PCA, which stands for Principal Component Analysis, is a statistical technique used for dimensionality reduction. It aims to transform a high-dimensional dataset into a lower-dimensional space while preserving the most important patterns and variances in the data\n",
    "\n",
    "Let's consider a dataset with five features: height, weight, age, income, and education level. We want to reduce the dimensionality of this dataset using PCA\n",
    "\n",
    "\n",
    "For instance, suppose that after applying PCA, we select two principal components that explain 90% of the total variance. We can then visualize the data in a two-dimensional space using these two components, effectively reducing the dimensionality of the original dataset.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98782abd-07e7-45e4-8e44-405f5c8eea76",
   "metadata": {},
   "source": [
    "#Q4\n",
    "'''PCA and feature extraction are closely related concepts. In fact, PCA can be used as a feature extraction technique itself.\n",
    "\n",
    "Feature extraction refers to the process of transforming the original features of a dataset into a new set of features that captures the most relevant information. The goal is to represent the data in a more compact and meaningful way, often by reducing the dimensionality of the feature space.\n",
    "\n",
    "PCA can be used as a feature extraction technique by identifying the principal components that explain the most variance in the data. These principal components serve as a reduced set of features that retain the essential patterns and information from the original dataset. By selecting a subset of the principal components, we effectively perform feature extraction.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f0a0c4-a845-41d1-b26a-aebea835f56d",
   "metadata": {},
   "source": [
    "#Q5\n",
    " Analyze the range and distribution of the features in the dataset, including price, rating, and delivery time. Identify the minimum and maximum values for each feature.\n",
    "\n",
    " Use the Min-Max scaling formula to transform the values of each feature to a common range, typically between 0 and 1. The formula for Min-Max scaling is:\n",
    "\n",
    "scaled_value = (value - min_value) / (max_value - min_value)\n",
    "\n",
    "For each feature, subtract the minimum value from each value and divide it by the difference between the maximum and minimum values.\n",
    "\n",
    " Apply the Min-Max scaling technique to all the relevant features in the dataset, such as price, rating, and delivery time. Scale each feature individually, using its respective minimum and maximum values.\n",
    "\n",
    " After applying Min-Max scaling, you will have a normalized dataset where all the features will fall within the range of 0 to 1. This normalization ensures that each feature contributes proportionally to the recommendation system without any dominance due to their original scales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98834bd8-54b5-4151-beb1-fdda53ea11fa",
   "metadata": {},
   "source": [
    "#Q6\n",
    "firstly we have to Understand the dataset :Preprocess the data :Standardize the data :Compute the covariance matrix :Perform PCA :Select the desired number of components :Project the data\n",
    ":Reduced dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5340cc-cea4-4518-af94-515c957d9ef1",
   "metadata": {},
   "source": [
    "#Q7\n",
    "To perform Min-Max scaling on the dataset [1, 5, 10, 15, 20] and transform the values to a range of -1 to 1, we need to determine the minimum and maximum values of the dataset and apply the Min-Max scaling formula.\n",
    "\n",
    "Minimum value: 1\n",
    "Maximum value: 20\n",
    "\n",
    "The Min-Max scaling formula is:\n",
    "scaled_value = (value - min_value) / (max_value - min_value)\n",
    "\n",
    "For 1:\n",
    "scaled_value = (1 - 1) / (20 - 1) = 0 / 19 = 0\n",
    "\n",
    "For 5:\n",
    "scaled_value = (5 - 1) / (20 - 1) = 4 / 19 ≈ 0.211\n",
    "\n",
    "For 10:\n",
    "scaled_value = (10 - 1) / (20 - 1) = 9 / 19 ≈ 0.474\n",
    "\n",
    "For 15:\n",
    "scaled_value = (15 - 1) / (20 - 1) = 14 / 19 ≈ 0.737\n",
    "\n",
    "For 20:\n",
    "scaled_value = (20 - 1) / (20 - 1) = 19 / 19 = 1\n",
    "\n",
    "The scaled values for the dataset [1, 5, 10, 15, 20] in the range of -1 to 1 using Min-Max scaling would be approximately [-1, -0.579, -0.053, 0.474, 1]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ba78a4-6e46-4617-b116-f4755d5bc3f4",
   "metadata": {},
   "source": [
    "#Q8\n",
    "Preprocess the data : Standardize the data : Compute the covariance matrix : Perform PCA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
